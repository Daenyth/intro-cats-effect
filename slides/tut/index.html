<!DOCTYPE html>
<html>

<head>
  <title>Intro to Cats-Effect</title>
  <meta charset="utf-8">
  <style>
    @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
    @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
    @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

    body {
      font-family: 'Droid Serif', 'Helvetica';
      /*line-height: 1.25em;*/
    }

    li {
      margin: 10px 0;
    }

    h1,
    h2,
    h3 {
      font-family: 'Yanone Kaffeesatz', 'Gill Sans';
      font-weight: normal;
    }

    img {
      width: 100%;
      height: 100%;
      object-fit: contain;
    }

    .remark-code,
    .remark-inline-code {
      font-family: 'Ubuntu Mono', 'Consolas', 'Courier New';
    }
  </style>
</head>

<body>
  <textarea id="source">

class: center, middle

# Intro to Cats-Effect
Gavin Bisesi â€¢ `@Daenyth`

Principal Engineer @ Teikametrics

???

Questions at the end

---
# What is a "Functional side effect" library?

--

Programming with "pure functions", aka programming with *Referential Transparency*

---
# Referential Transparency

--

A property of *expressions* (not statements (`return`) or declarations (`def`, `class`))

--

> The result of any expression can be replaced by its definition without changing the meaning

---
# Referential Transparency
> The result of any expression can be replaced by its definition without changing the meaning

```tut:book
val two = 1 + 1

two
1 + 1

```

ðŸ‘

---
# Referential Transparency
> The result of any expression can be replaced by its definition without changing the meaning

```tut:book
val hello = println("hello")

hello
println("hello")

```

ðŸ‘Ž

---
# Who cares? Why use FP?

Why program with Referential Transparency?

RT means we can:
- Read code and know what it means and what it does, without reading the rest of the codebase
- Change existing code without breaking it  

---
# Who cares? Why use FP?

In other words:

We use FP because we want a codebase that
- Developers can read and understand
- Can be changed without breaking things

(among other reasons)

---
# Functional Programming - Combinators

*Combinators* are composable building block functions that modify some input in a reusable way
- `map`
- `filter`

---
# Some setup
```tut:silent
import cats._
import cats.implicits._
import cats.effect._
import cats.effect.implicits._
import scala.concurrent._
import scala.concurrent.duration._

import ExecutionContext.Implicits.global
implicit val CS: ContextShift[IO] = IO.contextShift(global)
implicit val timer: Timer[IO] = IO.timer(global)

// Avoid this in real code!
def yolo[A](description: IO[A]) = description.unsafeRunSync()

```

```tut:invisible
import java.util.UUID
trait Database
```

---
# cats-effect `IO`

A lot like scala `Future` at first glance
- `apply` to wrap blocks of code
- `map`, `flatMap`
- Don't use `Await` with `Future`; don't use `unsafeRun*` with `IO`

```tut:book
val rndUUID: IO[UUID] = IO(UUID.randomUUID)
val helloIO = rndUUID.flatMap(uuid => IO(println(s"Hello $uuid")))

yolo(helloIO)
```

---
# `IO[A]` values

`IO[A]` describes a computation that will:
- Eventually produce a value of `A`, or
- Fail with a `Throwable`, or
- Never complete


---
# cats-effect typeclasses

All the capabilities that `IO` exposes are described by typeclasses, allowing more generic code and multi-library compatibility.

This talk focus on `IO` and not the typeclasses

---
# cats-effect typeclasses

<img src="typeclasses-cheat-sheet.png">

---
# `IO` vs `Future` - Overview

Actions:
- `IO` is a value that describes an action (possibly asynchronous)
- `Future` is a handle to the result of an already-running action (possibly asynchronous)

---
# `IO` vs `Future` - Speed

- `IO` is optimized for throughput
  - Thread shift on demand
  - Has utilities for introducing manual shifts for fairness
  - Benchmarks faster for most workloads
- `Future` is optimized for fairness
  - Thread shift every single `map`/`flatMap` (hence implicit `ec`)
  - Can only be configured using a specialized `ec` argument

---
# `IO` vs `Future` - Cancellation

- `Future[A]` can't be cancelled - once constructed, it can't be stopped
  - Wasted resources
- `IO[A]` can be concurrently forked, and then either `join`ed or `cancel`ed  
  - There are high-level constructs around this in cats-effect
  - More sophisticated abstractions built on top can be found in other libraries

---
# `IO` Execution

- Can describe both concurrency and parallelism
- Uses N:M green-threading
  - Cheap: thousands of concurrent `Fiber`s are not a problem
- Nonblocking asynchronous execution
  - Run as as few as 1 thread (including Scala.JS)

---
# IO Concurrency

Both low-level `Fibers` and high-level combinators
- Forking: `io.start`, `Fiber`
- Cancellation (low level): `Fiber#cancel`
- Cancellation (high level): 
  - `IO.race(first, second)` - concurrently execute, return the winner and cancel the loser,
  - `io.timeout(duration)` - fails with `TimeoutException` if not complete within `duration`
  - `io.timeoutTo(duration, fallbackIO)` - Execute `fallbackIO` if `io` is not complete within `duration`
- Nonblocking asynchronous sleep: `Timer[IO].sleep(duration)`
- Concurrent execution: `start`, `listOfIO.parSequence`, `(ioA, ioB).parTupled`

---
# `IO` vs `Future` - Concurrency

- Future has concurrency depending where you invoke functions
- IO has concurrency via explicit combinators

---
# `IO` vs `Future` - Concurrency with Future
```tut:silent
// Sequential execution
def jobOne: Future[Int] = Future(???)
def jobTwo: Future[String] = Future(???)

jobOne.flatMap(i => jobTwo.map(s => (i, s)))
```

```tut:silent
// Concurrent execution
val jobOne: Future[Int] = Future(???)
val jobTwo: Future[String] = Future(???)

jobOne.flatMap(i => jobTwo.map(s => (i, s)))
```

---
# `IO` vs `Future` - Concurrency with Future


Does this expression evaluate concurrently or sequentially?

```tut:silent
jobOne.flatMap(i => jobTwo.map(s => (i, s)))
```

Impossible to tell - have to read the implementation details

---
# `IO` vs `Future` - Concurrency with IO

```tut:silent
val jobOne: IO[Int] = IO(???)
val jobTwo: IO[String] = IO(???)

// Sequential execution
jobOne.flatMap(i => jobTwo.map(s => (i, s)))
// Also Sequential
val result: IO[(Int, String)] = (jobOne, jobTwo).tupled

// Concurrent execution (manually)
for {
  j1Fiber <- jobOne.start
  j2Fiber <- jobTwo.start
  i <- j1Fiber.join
  s <- j2Fiber.join
} yield (i, s)

// Concurrent execution (higher level)
val result: IO[(Int, String)] = (jobOne, jobTwo).parTupled

```

---
# Resource management

`Resource[IO, A]` describes the ability to initialize and release a resource
- Similar to `try`/`finally`, but composable and referentially transparent
  - `catch`/`finally` aren't transparent - they don't talk about *return values*.
- Allows tracking resource lifetime at the type level
  - Function accepting `Resource[IO, A]` parameter will acquire and release internally
  - Function accepting `A` reuses the live value
- Allows *guaranteed* finalization
  - Whether the function given to `use` completes, fails, or is cancelled, the Resource is closed. Will not leak.

---
# A tour of cats-effect:

- Utilities around Thread pools, controlling where and when things execute
  - ContextShift - A "pure" ExecutionContext parallel
  - Blocker - Used together with ContextShift to handle thread-blocking work.
  - Timer - Get the time, delay execution until a time
- Concurrency primitives
  - Semaphore - Has `N` permits, can acquire or release permits as needed. Acquire blocks until permits are available
  - Ref - Lock-free concurrency-safe mutable shared memory
  - Deferred - A pure promise. Can complete with a value or get the completed value. Get blocks until complete.
- `IOApp` - Whole "pure" applications


---
# Thread pool management

<img src="concurrency-thread-pools.png">

---
# Thread pool management

3 pool model
- Computation: Fixed size pool for cpu work
 - Used by `ContextShift[IO]`
- Blocking IO: Cached thread pool for thread-blocking work
 - Wrapped with `Blocker` for explicit use 
- Event Dispatcher: High-priority pool for scheduling and timers
 - Used by `Timer` to schedule sleeps
 - While transitioning away from `Futures` toward `IO`, we used the Computation pool (2 pool setup)

---
# Blocking threads

Blocking threads should be avoided
- Your cpu core is doing no work, waiting for a result while it could be computing something else
- It reduces your bandwidth for concurrent work

`Blocker` is a thin newtype around `ExecutionContext`

Used to clearly mark thread-blocking code in type signatures and prevent accidentally using the wrong thread pool
```scala
val blocker = Blocker.liftExecutionContext(global)
val fos: java.io.FileOutputStream = ???
val bytes: Array[Byte] = ???
val writeFile: IO[Unit] = blocker.blockOn(IO(fos.write(bytes)))
```

---
# Time

`Timer` and `Clock`
 - Nonblocking async sleep: `Timer[IO].sleep(duration)`
 - Get the time: `Clock[IO].realTime(MILLISECONDS)`
   - `Clock` comes from `Timer`; `timer.clock` or via implicit `Clock[IO]`


---
# Applications

`IOApp` for your "main" classes
- Provides an appropriate `ContextShift` and `Timer` for you

```tut:silent
object MyMain extends IOApp {
  def run(args: List[String]): IO[ExitCode] = {
    val myAppResource = 
      for {
        _ <- Resource.liftF(IO(println("hello cats")))
        db <- getDatabase
        blocker <- Blocker[IO]
        result <- Resource.liftF(myAppLogic(db, blocker))
        _ <- Resource.liftF(IO(println(s"got $result")))
      } yield ()
    
      myAppResource.use(_ => IO.pure(ExitCode.Success))
    }


  def getDatabase: Resource[IO, Database] = ???
  def myAppLogic(db: Database, blocker: Blocker): IO[Int] = ???
} 
```

---
# I already have an application!

`IO` can be introduced to a codebase using `Future` or using its own "main" class.

---
# Calling `Future` from `IO`

```tut:silent
def existingLogic(x: Int): Future[Int] = ???
def moreLogic(y: Int): IO[Int] =
  for {
    xResult <- IO.fromFuture(IO(existingLogic(42))) 
  } yield xResult + y
```

---

# Calling `IO` from `Future`

```tut:silent
trait MyTrait { def doWork: Future[Int] }

new MyTrait {
  override def doWork: Future[Int] =
  ioLogic.map(_.length).unsafeToFuture()
  
  def ioLogic: IO[String] = ???
}
```

---
# Converting to IO - Sequential imperative

Sequential code:
- Replace `;` with `flatMap`

```tut:silent

// Imperative
def oneStep(): Unit = println("one")
def anotherStep(): Unit = println("two")

oneStep()
anotherStep()

// IO
def oneStep(): IO[Unit] = IO(println("one"))
def anotherStep(): IO[Unit] = IO(println("two"))

for {
  _ <- oneStep()
  _ <- anotherStep()
} yield ()
```

---
# Converting to `IO` - `Future` code

- `Future.successful` -> `IO.pure`
- `Future.failed` -> `IO.raiseError`
- Implicit `Future` concurrency -> Explicit concurrency combinators
- Side effects in `map` -> explicit effects with `IO(sideEffect())` + `flatMap`
  - This is crucial
- Imperative init/close methods -> `Resource`

---
# Converting to `IO` - general tips
- Sometimes you'll want to `import cats.implicits._` for generic combinators (eg `tupled`, `handleError`)
- Sometimes you'll want `import cats.effect.implicits._` for effect methods (eg `parSequence`, `parTupled`, `parMapN`)
- `IO` concurrency requires `ContextShift[IO]` implicit
  - `IOApp` gives you one for free, otherwise `IO.contextShift(computeEC)`
- Time-based methods including sleep require `Timer[IO]` implicit
  - `IOApp` gives you one for free, otherwise `IO.timer(eventDispatcherEC)` (if you have one) or `IO.timer(computeEC)` if you don't
- Try not to use a fork-join pool for `ContextShift` - you're leaving performance on the table by creating too many threads  
- Understand the risks when using `.unsafe*` methods on `IO`

---
# Converting to `IO` - Common errors
- Side effects not wrapped `IO`, eg in `map`
- Implicit `Future` concurrency
- Use `-Ywarn-value-discard`!
  - Optionally, set a lot of "save me from myself" flags at once using `sbt-tpolecat`

---
# Converting to `IO` - Application structure
- Semantic interfaces, not mechanical ones
- New code in `IO`
- Interop where needed
- Convert one class at a time
  - You don't need to convert the whole project!
  - Stop whenever you reach "good enough"
  - Update code sections when you need to; if it's not broken and isn't being modified, leave it

---
# Cats-Effect

- Write code that doesn't break when you change it
- Write reusable code that you know won't surprise you
- Write code that can be understood in isolation
- Gain access to an ecosystem of compatible, efficient, and easy to learn libraries

---
# Links and resources

- [Tutorial](https://typelevel.org/cats-effect/tutorial/tutorial.html)
- typelevel/cats-effect [Gitter chat](http://gitter.im/typelevel/cats-effect)
- [Documentation](https://typelevel.org/cats-effect/)
- [Functional and Reactive Domain Modeling](https://www.manning.com/books/functional-and-reactive-domain-modeling)
  - Book that goes into application design, in a style that meshes very cleanly with cats-effect
- [Referential Transparency in the Wild](https://impurepics.com/posts/2018-07-13-referential-transparency-wild.html)
- [Shared State in Functional Programming](https://typelevel.org/blog/2018/06/07/shared-state-in-fp.html) - More examples around `Resource` usage and simpler data sharing examples
- [@impurepics](https://impurepics.com) is the author+owner of the graphics
    


---
class: center, middle

# Thanks!
Code and slides at `daenyth/intro-cats-effect` on GitHub

## Questions?





 </textarea>
  <script src="remark-latest.min.js">
  </script>
  <script>
    var slideshow = remark.create();
  </script>
</body>

</html>